{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7157770-2bef-4857-a65b-f1db8b32b763",
   "metadata": {},
   "source": [
    "_**NOTE: Unfinished notebook. The kernel got suspsended during similarity calculation**_\n",
    "\n",
    "_TODO: Fix bug_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36819fac-02ad-4756-9e94-0347aaa50e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "143e2b4a-8675-44d9-a2a7-0eaaefed2a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x158ac4be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model_dir = \"./models\"\n",
    "model_h5_file = os.path.join(model_dir, \"model_task_2_cnn_classification.h5\")\n",
    "\n",
    "model = load_model(model_h5_file)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f09745-96b2-4701-83c6-9e856bc201ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 88\n",
    "\n",
    "def get_histogram(image: np.ndarray):\n",
    "    histogram = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "    histogram = cv2.normalize(histogram, histogram).flatten()\n",
    "    return histogram \n",
    "\n",
    "def get_texture_feature(image: np.ndarray):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    glcm = texture.haralick(gray_image)\n",
    "    return np.mean(glcm, axis=0)\n",
    "\n",
    "def get_compactness(image: np.ndarray):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresholded = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate compactness for each contour\n",
    "    compactness_values = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        compactness = perimeter / np.sqrt(area) if area > 0 else 0\n",
    "        compactness_values.append(compactness)\n",
    "    \n",
    "    # Maximum Compactness: Choose the contour with the highest compactness value. \n",
    "    # This approach assumes that the object with the highest compactness is the most significant or relevant in the image.\n",
    "    max_compactness_index = np.argmax(compactness_values)\n",
    "    max_compactness_value = compactness_values[max_compactness_index]\n",
    "    \n",
    "    return max_compactness_value\n",
    "\n",
    "\n",
    "def get_similarity_attrs(row: pd.Series) -> pd.Series: \n",
    "    print(row['path'])\n",
    "    image = cv2.imread(row['path'])\n",
    "\n",
    "    row['histogram'] = get_histogram(image)\n",
    "    row['texture_feature'] = get_texture_feature(image)\n",
    "    row['compactness'] = get_compactness(image)\n",
    "\n",
    "    return row \n",
    "\n",
    "df_similarity = df.progress_apply(get_similarity_attrs, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
